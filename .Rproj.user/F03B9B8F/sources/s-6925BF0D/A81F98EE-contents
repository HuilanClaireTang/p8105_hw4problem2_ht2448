---
title: "Homework 2 solutions"
author: "Jeff Goldsmith"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output:
  html_document: 
    toc: true
    toc_float: true
hitheme: tomorrow
highlighter: highlight.js

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

### Due date

Due: October 4 at 5:00pm. 

### Points

* Problem 0: 10 points
* Problem 1: 30 points
* Problem 2: 30 points
* Problem 3: 30 points

### Problem 0

This "problem" focuses on structure of your assignment, including the use of R Markdown to write reproducible reports, the use of R Projects to organize your work, the use of relative paths to load data, and the naming structure for your files. 

To that end: 

* create a directory named `p8105_hw2_YOURUNI` (e.g. `p8105_h21_ajg2202` for Jeff)
* put an R project in the directory
* create a single .Rmd file named `p8105_hw2_YOURUNI.Rmd`

Some of the datasets used in this homework are large, so you should not include raw data files in your directory. Instead, create a separate directory called `data` and use relative paths starting with `../data/` to load data. We'll have a similar directory and should be able to knit your R Markdown file. 

```{r load_libraries}
library(tidyverse)
library(readxl)
library(janitor)
library(DT)
```

### Problem 1

First we clean the Mr. Trash Wheel dataset and round the number of sports balls to the nearest integer.

```{r clean_trash}
mr_trash_wheel = read_excel("../data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
           sheet = "Mr. Trash Wheel", range = cell_cols("A:N")) %>%
  clean_names() %>%
  filter(!is.na(dumpster)) %>%
  mutate(sports_balls = round(sports_balls),
         sports_balls = as.integer(sports_balls))

str(mr_trash_wheel)
```

Next we read clean precipitation data for 2016 and 2017, omit rows without precipitation data, add a variable year, combine datasets, and convert month to a character variable.

```{r clean_precipitation}
precip_2016 = 
  read_excel("../data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
             sheet = "2016 Precipitation", skip = 1) %>%
  clean_names() %>%
  filter(!is.na(month)) %>%
  mutate(year = 2016)

precip_2017 = 
  read_excel("../data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
             sheet = "2017 Precipitation", skip = 1) %>%
  clean_names() %>%
  filter(!is.na(total)) %>%
  mutate(year = 2017)

precip = bind_rows(precip_2016, precip_2017) %>%
  mutate(month = month.name[month])

str(precip)
```

So what's going on in these datasets? First we examine Mr. Trash Wheel. This dataset has `r nrow(mr_trash_wheel)` observations and `r ncol(mr_trash_wheel)` variables. Other than `month` and `date`, all variables are class `integer` or `numeric`. Number of sports balls is the only integer class variable. In 2016, the **median number of sports balls found in a dumpster was `r mr_trash_wheel %>% filter(year == 2016) %>% pull(sports_balls) %>% median()`**. 

The precipitation data has `r nrow(precip)` observations and `r ncol(precip)` variables, the only variables in the dataset being `month`, `total` for total precipitation, and `year`. The **total precipitation in 2017 was `r filter(precip, year == 2017) %>% pull(total) %>% sum()` inches**.


### Problem 2

Next we clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. Note that we code values for which `prez_gop` is `2` we code the new variable `president` as `gop` -- these are months in which Ford became President following Nixon's resignation.

```{r clean_538_pols}
pols = read_csv("../data/fivethirtyeight_datasets/pols-month.csv") %>%
  separate(mon, into = c("year", "month", "day"), convert = TRUE) %>%
  mutate(month = month.name[month], 
         president = recode(prez_gop, `0` = "dem", `1` = "gop", `2` = "gop")) %>%
  select(-day, -starts_with("prez"))
```

We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r clean_538_snp}
snp = read_csv("../data/fivethirtyeight_datasets/snp.csv") %>%
  separate(date, into = c("month", "day", "year"), convert = TRUE) %>%
  arrange(year, month) %>%
  mutate(month = month.name[month]) %>%
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_538_unemp}
unemployment = read_csv("../data/fivethirtyeight_datasets/unemployment.csv") %>%
  rename(year = Year) %>%
  gather(key = month, value = unemployment, Jan:Dec) %>%
  mutate(month = recode(month, 
                        Jan = "January", 
                        Feb = "February",
                        Mar = "March",
                        Apr = "April",
                        May = "May",
                        Jun = "June",
                        Jul = "July",
                        Aug = "August",
                        Sep = "September",
                        Oct = "October",
                        Nov = "November",
                        Dec = "December"))
```

Now we merge the three datasets!

```{r merge_538}
data_538 = left_join(pols, snp) %>%
  left_join(., unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r range(pols$year)[1]` to `r range(pols$year)[2]`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r range(snp$year)[1]` to `r range(snp$year)[2]`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r range(unemployment$year)[1]` to `r range(unemployment$year)[2]`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") %>% pull(unemployment) %>% mean() %>% round(., 2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") %>% pull(unemployment) %>% mean() %>% round(., 2)`.

### Problem 3

First we read and unzip the instacart data.

```{r read_instacart}
instacart = read_csv("../data/instacart_train_data.csv.zip")
```

Next we answer some questions about the instacart data.

* How many entries are in the dataset?
    * How many unique orders?

There are `r dim(instacart)[1]` entries in the dataset and `r instacart %>% pull(order_id) %>% unique() %>% length()` unique orders.

* Make a histogram of order hour for items from the produce department.

Histogram shown below:

```{r hist_order_hour}
instacart %>% 
  filter(department == "produce") %>% 
  pull(order_hour_of_day) %>% 
  hist(main = "Order hours for items from produce department", col = "forestgreen", border = "orange")
```

* How are aisles related to departments? 

```{r insta_aisles}
instacart %>% 
  select(department, aisle) %>%
  distinct() %>%
  arrange(department, aisle) %>% DT::datatable() # could also have loaded library(DT) in first code chunk
```

--

We can look through the data table above to see how aisles are related to department. For example, the breakfast department contains cereal, granola, and pancake mixes. Aisles only appear in a single department, and every aisle is in a department.

* From what department are the most items ordered? 
    * From what department are the least items ordered?
    
```{r min_and_max}
max = max(table(instacart$department))
min = min(table(instacart$department))

max_department = table(instacart$department)[which(table(instacart$department) == max)]
min_department = table(instacart$department)[which(table(instacart$department) == min)]
```

The most items, `r  max_department %>% as.integer`, are delivered from the `r names(max_department)` department and fewest items are delivered from the `r names(min_department)` department, at `r  min_department %>% as.numeric` items.

  
* What is the median number of days since the prior order? 

```{r median_days_prior}
median_days = instacart %>%
  select(order_id, days_since_prior_order) %>%
  distinct() %>%
  pull(days_since_prior_order) %>%
  median
```

The median number of days since the prior order is `r median_days`.

* What is the median hour of the day at which Pink Lady Apples are ordered? 
    * What about Coffee Ice Cream?
    
```{r median_foods}
median_apples = instacart %>%
  filter(product_name == "Pink Lady Apples") %>%
  pull(order_hour_of_day) %>% 
  median()

median_coffee = instacart %>%
  filter(product_name == "Coffee Ice Cream") %>%
  pull(order_hour_of_day) %>% 
  median()
```

Pink lady apples are ordered at a median hour of `r median_apples`. The median hour of the day to order coffee ice cream, arguably the best type of ice cream, is `r median_coffee`. People tend to order pink lady apples earlier in the day than they order coffee ice cream.

